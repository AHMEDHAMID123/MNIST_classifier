{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "543e8a13",
   "metadata": {},
   "source": [
    "# MNIST dataset for hand written digits\n",
    "### important remarks\n",
    "- The data has 60000 image\n",
    "- Eachh category has around the same number of data points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b5ad2d75",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.vision.all import *\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1d152b99",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = untar_data(URLs.MNIST)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cc7ba839",
   "metadata": {},
   "outputs": [],
   "source": [
    "#function convert the image files in a certain path into a list of tensors and save them in a dictionary\n",
    "def data_tensors(path):\n",
    "    files = os.listdir(path)\n",
    "    Urls = (path).ls()\n",
    "    data_set = {}\n",
    "    for i, j in zip(files, Urls):\n",
    "        data_set[i] = [tensor(Image.open(im)) for im in j.ls()]\n",
    "    return data_set\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1af32fb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train = data_tensors(path/\"training\")\n",
    "data_test = data_tensors(path/\"testing\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0bb43f71",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = lambda x: torch.stack(x)\n",
    "\n",
    "data_train = {i : f(j) for i, j in data_train.items()}\n",
    "data_test = {i : f(j) for i, j in data_test.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "936e956f",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = torch.cat(list(data_train.values())).view(-1, 28*28).float()/255\n",
    "y_train = torch.cat( [tensor([int(i)]*len(data[i])) for i in list(data.keys())])\n",
    "\n",
    "x_test = torch.cat(list(data_test.values())).view(-1, 28*28).float()/255\n",
    "y_test = torch.cat( [tensor([int(i)]*len(data_test[i])) for i in list(data_test.keys())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "d3623d59",
   "metadata": {},
   "outputs": [],
   "source": [
    "#simple sequantial neural netwrok model\n",
    "neural_net = nn.Sequential(\n",
    "nn.Linear(28*28, 550),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(550, 350),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(350, 200),\n",
    "nn.ReLU(),\n",
    "nn.Linear(200, 100),\n",
    "nn.ReLU(),\n",
    "nn.Linear(100,60),\n",
    "nn.ReLU(),\n",
    "nn.Linear(60, 30),\n",
    "nn.ReLU(),\n",
    "nn.Linear(30, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "146aad7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "des_t = list(zip(x_train, y_train))\n",
    "des_val = list(zip(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "a7d61b99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# using fastai data loaders for batching the training data\n",
    "dl_t = DataLoader(des_t, batch_size= 125, shuffle =  True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "fcc585c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss function used for otimization\n",
    "#using the entropy loss function from pytorch\n",
    "\n",
    "def loss_function(preds, yb):\n",
    "    loss = F.cross_entropy(preds,yb.squeeze())\n",
    "    return loss\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "d7a93768",
   "metadata": {},
   "outputs": [],
   "source": [
    "# optimizer class to do the optimization steps\n",
    "class optmizer:\n",
    "    def __init__ (self, parameters, lr):\n",
    "        self.parameters = list(parameters)\n",
    "        self.lr = lr\n",
    "    def step(self, *args, **kwargs):\n",
    "        for p in self.parameters:\n",
    "            p.data -= p.grad.data * self.lr\n",
    "            \n",
    "    def set_zero(self,*args, **kwargs ):\n",
    "        for p in self.parameters:\n",
    "            p.grad = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a92162f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate the accurecy the predections \n",
    "def _accurecy(pred, targets):\n",
    "    preds = torch.argmax(pred.softmax(1),1)\n",
    "    return (preds == targets).float().mean()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "e4f6333b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#stocastic gredient descent function\n",
    "def sgd(xb , yb , model):\n",
    "    preds = model(xb)\n",
    "    loss = loss_function(preds, yb)\n",
    "    loss.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "9da3f4a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#training for one epochs\n",
    "def train_epochs(dl, model , prt = False):\n",
    "    \n",
    "    for xb,yb in dl:\n",
    "        sgd(xb,yb, model)\n",
    "        opt.step()\n",
    "        opt.set_zero()\n",
    "        if prt:\n",
    "            print(\"batch_accurecy = {:.3f}\".format(_accurecy(model(xb) , yb)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "fa6c8ff2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_training(dl , model, epochs):\n",
    "    for i in range(epochs):\n",
    "        train_epochs(dl, model)\n",
    "        print(\"epoch {} accuracy = {:.3f}\".format(i ,_accurecy(model(x_test), y_test)))\n",
    "      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "80284827",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0 accuracy = 0.207\n",
      "epoch 1 accuracy = 0.534\n",
      "epoch 2 accuracy = 0.937\n",
      "epoch 3 accuracy = 0.949\n",
      "epoch 4 accuracy = 0.960\n",
      "epoch 5 accuracy = 0.966\n",
      "epoch 6 accuracy = 0.969\n",
      "epoch 7 accuracy = 0.972\n",
      "epoch 8 accuracy = 0.974\n",
      "epoch 9 accuracy = 0.973\n"
     ]
    }
   ],
   "source": [
    "opt= optmizer(neural_net.parameters(), .1)\n",
    "model_training(dl_t, neural_net, 10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
